{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b74c98f2-1001-4a4d-9e9e-c8e1a0aef803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Description: Pembayaran S    H F\n",
      "Cleaned Description: Pembayaran S H F\n",
      "Corrected Description: Pembayaran S H F\n",
      "Normalized Description: pembayaran s h f\n",
      "Handled Description: pembayaran s h f\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import textdistance\n",
    "\n",
    "# Function to remove extra spaces and newlines\n",
    "def remove_extra_spaces(text):\n",
    "    return re.sub(r'\\s+', ' ', text.strip())\n",
    "\n",
    "# Function to correct typos using fuzzy string matching\n",
    "def correct_typos(text, reference_texts):\n",
    "    corrected_text = text\n",
    "    for ref_text in reference_texts:\n",
    "        similarity = textdistance.jaccard(text.lower(), ref_text.lower())\n",
    "        if similarity > 0.8:  # Adjust similarity threshold as needed\n",
    "            corrected_text = ref_text\n",
    "            break\n",
    "    return corrected_text\n",
    "\n",
    "# Function to normalize text by converting to lowercase and removing non-alphanumeric characters\n",
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# Function to handle missing descriptions by replacing them with a placeholder\n",
    "def handle_missing_descriptions(text, placeholder=\"[MISSING]\"):\n",
    "    return text if text else placeholder\n",
    "\n",
    "# Example usage\n",
    "description = \"Pembayaran S    H F\"\n",
    "reference_texts = [\"fidusia\", \"fiducia\", \"fiducya\"]  # List of reference texts for fuzzy string matching\n",
    "cleaned_description = remove_extra_spaces(description)\n",
    "corrected_description = correct_typos(cleaned_description, reference_texts)\n",
    "normalized_description = normalize_text(corrected_description)\n",
    "handled_description = handle_missing_descriptions(normalized_description)\n",
    "\n",
    "print(\"Original Description:\", description)\n",
    "print(\"Cleaned Description:\", cleaned_description)\n",
    "print(\"Corrected Description:\", corrected_description)\n",
    "print(\"Normalized Description:\", normalized_description)\n",
    "print(\"Handled Description:\", handled_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e598581-f57c-4997-bf8b-e8b97682eb8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "277a0da8-693b-42f8-863d-4b6f6cd2ee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import textdistance\n",
    "\n",
    "# Function to remove extra spaces and newlines\n",
    "def remove_extra_spaces(text):\n",
    "    # Replace consecutive spaces and newlines with a single space\n",
    "    return re.sub(r'\\s+', ' ', text.strip())\n",
    "\n",
    "# Function to correct typos using techniques like spell-checking or fuzzy string matching\n",
    "def correct_typos(text, dataset_texts):\n",
    "    corrected_words = []\n",
    "    for word in text.split():\n",
    "        max_similarity = 0\n",
    "        corrected_word = word\n",
    "        for dataset_word in dataset_texts:\n",
    "            similarity = textdistance.levenshtein.normalized_similarity(word.lower(), dataset_word.lower())\n",
    "            if similarity > max_similarity:\n",
    "                corrected_word = dataset_word\n",
    "                max_similarity = similarity\n",
    "        corrected_words.append(corrected_word)\n",
    "    return ' '.join(corrected_words)\n",
    "\n",
    "# Function to normalize text by converting to lowercase and removing non-alphanumeric characters\n",
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# Function to handle missing descriptions by replacing them with a placeholder\n",
    "def handle_missing_descriptions(text, placeholder=\"[MISSING]\"):\n",
    "    return text if text else placeholder\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('dummy.csv')\n",
    "\n",
    "# Step 1: Preprocess text data\n",
    "# Clean the \"Deskripsi\" column\n",
    "df['Deskripsi'] = df['Deskripsi'].apply(remove_extra_spaces)\n",
    "\n",
    "# Extract all individual words from the \"Deskripsi\" column\n",
    "all_words = ' '.join(df['Deskripsi']).split()\n",
    "dataset_texts = list(set(all_words))  # Get unique words\n",
    "\n",
    "# Step 2: Correct typos in the \"Deskripsi\" column\n",
    "df['Deskripsi'] = df['Deskripsi'].apply(lambda x: correct_typos(x, dataset_texts))\n",
    "\n",
    "# Step 3: Normalize text data\n",
    "df['Deskripsi'] = df['Deskripsi'].apply(normalize_text)\n",
    "\n",
    "# Step 4: Handle missing descriptions\n",
    "df['Deskripsi'] = df['Deskripsi'].apply(handle_missing_descriptions)\n",
    "\n",
    "# Step 5: Combine preprocessed text data and numerical data\n",
    "X_text = df['Deskripsi'].values\n",
    "X_numeric = df['Nominal'].values\n",
    "y = df['Verifikasi'].values\n",
    "\n",
    "# Your remaining code for model training and evaluation goes here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafb5df7-397d-4334-bd8f-57ba714a1348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983e34d3-54f7-42c4-bf9c-444942caaeec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc7a96fd-b53b-4b1c-8d01-3586e4fcb6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Description: fi    du   sia\n",
      "Cleaned Description: fi du sia\n",
      "Corrected Description: F u fidusia\n",
      "Normalized Description: f u fidusia\n",
      "Handled Description: f u fidusia\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import textdistance\n",
    "\n",
    "# Function to remove extra spaces and newlines\n",
    "def remove_extra_spaces(text):\n",
    "    # Replace consecutive spaces and newlines with a single space\n",
    "    return re.sub(r'\\s+', ' ', text.strip())\n",
    "\n",
    "# Function to correct typos using techniques like spell-checking or fuzzy string matching\n",
    "def correct_typos(text, dataset_texts):\n",
    "    corrected_words = []\n",
    "    for word in text.split():\n",
    "        max_similarity = 0\n",
    "        corrected_word = word\n",
    "        for dataset_word in dataset_texts:\n",
    "            similarity = textdistance.levenshtein.normalized_similarity(word.lower(), dataset_word.lower())\n",
    "            if similarity > max_similarity:\n",
    "                corrected_word = dataset_word\n",
    "                max_similarity = similarity\n",
    "        corrected_words.append(corrected_word)\n",
    "    return ' '.join(corrected_words)\n",
    "\n",
    "# Function to normalize text by converting to lowercase and removing non-alphanumeric characters\n",
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# Function to handle missing descriptions by replacing them with a placeholder\n",
    "def handle_missing_descriptions(text, placeholder=\"[MISSING]\"):\n",
    "    return text if text else placeholder\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('dummy.csv')\n",
    "\n",
    "# Step 1: Preprocess text data\n",
    "# Clean the \"Deskripsi\" column\n",
    "df['Deskripsi'] = df['Deskripsi'].apply(remove_extra_spaces)\n",
    "\n",
    "# Extract all individual words from the \"Deskripsi\" column\n",
    "all_words = ' '.join(df['Deskripsi']).split()\n",
    "dataset_texts = list(set(all_words))  # Get unique words\n",
    "\n",
    "# Step 2: Correct typos in the \"Deskripsi\" column\n",
    "df['Deskripsi'] = df['Deskripsi'].apply(lambda x: correct_typos(x, dataset_texts))\n",
    "\n",
    "# Step 3: Normalize text data\n",
    "df['Deskripsi'] = df['Deskripsi'].apply(normalize_text)\n",
    "\n",
    "# Step 4: Handle missing descriptions\n",
    "df['Deskripsi'] = df['Deskripsi'].apply(handle_missing_descriptions)\n",
    "\n",
    "# Example usage\n",
    "description = \"fi    du   sia\"\n",
    "cleaned_description = remove_extra_spaces(description)\n",
    "corrected_description = correct_typos(cleaned_description, dataset_texts)\n",
    "normalized_description = normalize_text(corrected_description)\n",
    "handled_description = handle_missing_descriptions(normalized_description)\n",
    "\n",
    "print(\"Original Description:\", description)\n",
    "print(\"Cleaned Description:\", cleaned_description)\n",
    "print(\"Corrected Description:\", corrected_description)\n",
    "print(\"Normalized Description:\", normalized_description)\n",
    "print(\"Handled Description:\", handled_description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06f1f48e-f8a6-447d-827b-3cc39234fe3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u',\n",
       " 'pinalty',\n",
       " 'settlement',\n",
       " 'Pembayaran',\n",
       " 'm',\n",
       " 'setelment',\n",
       " 'SHF',\n",
       " 'fidusia',\n",
       " 'ty',\n",
       " 'fiducia',\n",
       " 'abcaba',\n",
       " '!@#',\n",
       " 'Pembyaran',\n",
       " 'jabotabek',\n",
       " 'F',\n",
       " 'k',\n",
       " 'setlement',\n",
       " 'abc',\n",
       " 'umk',\n",
       " 'S',\n",
       " 'pinalti',\n",
       " 'pi',\n",
       " 'abcabafidusia',\n",
       " '3',\n",
       " 'abca',\n",
       " 'abcabcabc',\n",
       " 'H',\n",
       " 'nal',\n",
       " 'cabang']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffa1061-56e4-4044-8968-a5779b2a3d30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
