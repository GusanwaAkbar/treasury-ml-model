{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d977a756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Deskripsi  Nominal Verifikasi\n",
      "0                                     Pembayaran SHF      200        SHF\n",
      "1                                Pembayaran S    H F      200        SHF\n",
      "2  Pembyaran S                                   ...      210        SHF\n",
      "3                                          abcabcabc      250        SHF\n",
      "4                        settlement cabang jabotabek      200    BUF/BUP\n",
      "\n",
      "y_test original indices:\n",
      "Int64Index([10, 6, 19, 2, 14], dtype='int64')\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [19, 15]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Random Forest Model\u001b[39;00m\n\u001b[1;32m     58\u001b[0m rf_model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 59\u001b[0m \u001b[43mrf_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVerifikasi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Prediction\u001b[39;00m\n\u001b[1;32m     62\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m rf_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:348\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 348\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/utils/validation.py:1164\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1146\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1147\u001b[0m     X,\n\u001b[1;32m   1148\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1160\u001b[0m )\n\u001b[1;32m   1162\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m-> 1164\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/utils/validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    405\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    410\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [19, 15]"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Read data from CSV\n",
    "df = pd.read_csv('dummy.csv')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(df.head())\n",
    "\n",
    "# Identify unique categories\n",
    "unique_categories = df['Verifikasi'].unique()\n",
    "\n",
    "# Initialize empty dataframes for training and testing\n",
    "df_train = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "\n",
    "# Select one data point per category for testing\n",
    "for category in unique_categories:\n",
    "    # Get one data point for testing\n",
    "    one_data_point = df[df['Verifikasi'] == category].sample(1, random_state=42)\n",
    "    \n",
    "    # Add to testing set\n",
    "    df_test = pd.concat([df_test, one_data_point], ignore_index=True)\n",
    "    \n",
    "    # Add the rest to the training set\n",
    "    df_train = pd.concat([df_train, df[df['Verifikasi'] != category]])\n",
    "\n",
    "# Randomize the test data when splitting\n",
    "df_train, df_test = train_test_split(df, test_size=0.25, shuffle=True, random_state=42, stratify=df['Verifikasi'])\n",
    "\n",
    "# Display original indices of y_test before splitting\n",
    "print(\"\\ny_test original indices:\")\n",
    "print(df_test.index)\n",
    "print('\\n')\n",
    "\n",
    "# Text Preprocessing\n",
    "vectorizer = CountVectorizer()\n",
    "X_text_train = vectorizer.fit_transform(df_train['Deskripsi'])\n",
    "X_text_test = vectorizer.transform(df_test['Deskripsi'])\n",
    "\n",
    "# Combine text features with numerical features\n",
    "X_train = pd.concat([pd.DataFrame(X_text_train.toarray()), df_train[['Nominal']].astype(str)], axis=1)\n",
    "X_test = pd.concat([pd.DataFrame(X_text_test.toarray()), df_test[['Nominal']].astype(str)], axis=1)\n",
    "\n",
    "# Convert column names to strings\n",
    "X_train.columns = X_train.columns.astype(str)\n",
    "X_test.columns = X_test.columns.astype(str)\n",
    "\n",
    "# Handle missing values in numerical features\n",
    "X_train = X_train.fillna(0)  # Replace NaN with 0 for simplicity\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "# Random Forest Model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, df_train['Verifikasi'])\n",
    "\n",
    "# Prediction\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(df_test['Verifikasi'], y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(df_test['Verifikasi'], y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d507681e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0    1    2    3    4    5    6    7    8    9   10   11   12   13   14  \\\n",
      "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "2   0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
      "3   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "4   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
      "5   1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "6   0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "7   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "8   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "9   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
      "10  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "11  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
      "12  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
      "13  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "14  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "18  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "15  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "17  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "16  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "     15   16   17  Nominal  \n",
      "0   0.0  0.0  0.0      200  \n",
      "1   0.0  0.0  0.0      200  \n",
      "2   1.0  0.0  0.0        0  \n",
      "3   0.0  0.0  0.0      250  \n",
      "4   0.0  0.0  0.0      200  \n",
      "5   0.0  0.0  0.0      300  \n",
      "6   0.0  1.0  0.0        0  \n",
      "7   0.0  0.0  0.0  1000000  \n",
      "8   0.0  0.0  1.0  2000000  \n",
      "9   0.0  0.0  0.0  2001000  \n",
      "10  0.0  0.0  0.0        0  \n",
      "11  0.0  0.0  0.0  2100000  \n",
      "12  0.0  0.0  0.0  1000000  \n",
      "13  0.0  0.0  1.0  2000000  \n",
      "14  0.0  0.0  0.0        0  \n",
      "18  0.0  0.0  0.0  3000000  \n",
      "15  0.0  0.0  0.0  3000000  \n",
      "17  0.0  0.0  0.0  2000000  \n",
      "16  0.0  0.0  0.0  1000000  \n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f5def7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Deskripsi  Nominal Verifikasi\n",
      "12                            pinalti  1000000    pinalty\n",
      "18  u     !@#     m    !@#       k  3  3000000       umk3\n",
      "5                  sett      tle ment      300    BUF/BUP\n",
      "9                             fiducia  2001000    fidusia\n",
      "13                            pinalty  2000000    pinalty\n",
      "11                         abcabacaca  2100000    fidusia\n",
      "15                          pi nal ty  3000000    pinalty\n",
      "1                 Pembayaran S    H F      200        SHF\n",
      "17                              umk 3  2000000       umk3\n",
      "7                           setelment  1000000    BUF/BUP\n",
      "3                           abcabcabc      250        SHF\n",
      "0                      Pembayaran SHF      200        SHF\n",
      "4         settlement cabang jabotabek      200    BUF/BUP\n",
      "16                              umk 3  1000000       umk3\n",
      "8                             fiducia  2000000    fidusia\n"
     ]
    }
   ],
   "source": [
    "print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8097d7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Deskripsi  Nominal Verifikasi\n",
      "0                                     Pembayaran SHF      200        SHF\n",
      "1                                Pembayaran S    H F      200        SHF\n",
      "2  Pembyaran S                                   ...      210        SHF\n",
      "3                                          abcabcabc      250        SHF\n",
      "4                        settlement cabang jabotabek      200    BUF/BUP\n",
      "Accuracy: 0.80\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     BUF/BUP       0.00      0.00      0.00         1\n",
      "         SHF       0.50      1.00      0.67         1\n",
      "     fidusia       1.00      1.00      1.00         1\n",
      "     pinalty       1.00      1.00      1.00         1\n",
      "        umk3       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.80         5\n",
      "   macro avg       0.70      0.80      0.73         5\n",
      "weighted avg       0.70      0.80      0.73         5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gusanwa/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gusanwa/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gusanwa/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Read data from CSV\n",
    "df = pd.read_csv('dummy.csv')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(df.head())\n",
    "\n",
    "# Text Preprocessing\n",
    "vectorizer = CountVectorizer()\n",
    "X_text = vectorizer.fit_transform(df['Deskripsi'])\n",
    "\n",
    "# Combine text features with numerical features\n",
    "X_numerical = pd.concat([pd.DataFrame(X_text.toarray()), df[['Nominal']].astype(str)], axis=1)\n",
    "\n",
    "# Convert column names to strings\n",
    "X_numerical.columns = X_numerical.columns.astype(str)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_numerical, df['Verifikasi'], test_size=0.25, random_state=42, stratify=df['Verifikasi'])\n",
    "\n",
    "# Random Forest Model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce937846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Deskripsi  Nominal Verifikasi\n",
      "0                                     Pembayaran SHF      200        SHF\n",
      "1                                Pembayaran S    H F      200        SHF\n",
      "2  Pembyaran S                                   ...      210        SHF\n",
      "3                                          abcabcabc      250        SHF\n",
      "4                        settlement cabang jabotabek      200    BUF/BUP\n",
      "\n",
      "Test Data:\n",
      "             Deskripsi  Nominal Verifikasi\n",
      "0  Pembayaran S    H F      200        SHF\n",
      "1   sett      tle ment      300    BUF/BUP\n",
      "2              fiducia  2001000    fidusia\n",
      "3              pinalty  2000000    pinalty\n",
      "4                umk 3  2000000       umk3\n",
      "\n",
      "Training Data:\n",
      "                      Deskripsi  Nominal Verifikasi\n",
      "4   settlement cabang jabotabek      200    BUF/BUP\n",
      "5            sett      tle ment      300    BUF/BUP\n",
      "6                     setlement      500    BUF/BUP\n",
      "7                     setelment  1000000    BUF/BUP\n",
      "8                       fiducia  2000000    fidusia\n",
      "..                          ...      ...        ...\n",
      "11                   abcabacaca  2100000    fidusia\n",
      "12                      pinalti  1000000    pinalty\n",
      "13                      pinalty  2000000    pinalty\n",
      "14                    pi nal ty  3000000    pinalty\n",
      "15                    pi nal ty  3000000    pinalty\n",
      "\n",
      "[80 rows x 3 columns]\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m X_text_test \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mtransform(df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeskripsi\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Combine text features with numerical features\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_text_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNominal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m X_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([pd\u001b[38;5;241m.\u001b[39mDataFrame(X_text_test\u001b[38;5;241m.\u001b[39mtoarray()), df_test[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNominal\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Convert column names to strings\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/pandas/core/reshape/concat.py:381\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03mConcatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m1   3   4\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    368\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    369\u001b[0m     objs,\n\u001b[1;32m    370\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    378\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    379\u001b[0m )\n\u001b[0;32m--> 381\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/pandas/core/reshape/concat.py:612\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    610\u001b[0m         obj_labels \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m ax]\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_labels\u001b[38;5;241m.\u001b[39mequals(obj_labels):\n\u001b[0;32m--> 612\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m \u001b[43mobj_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    614\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[1;32m    616\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[1;32m    617\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m    618\u001b[0m )\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/pandas/core/indexes/base.py:3904\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[1;32m   3903\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[0;32m-> 3904\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requires_unique_msg)\n\u001b[1;32m   3906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   3907\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Read data from CSV\n",
    "df = pd.read_csv('dummy.csv')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(df.head())\n",
    "\n",
    "# Initialize empty dataframes for training and testing\n",
    "df_train = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "\n",
    "# Select one random data point per category for testing\n",
    "for category in df['Verifikasi'].unique():\n",
    "    # Get one random data point for testing\n",
    "    one_data_point = df[df['Verifikasi'] == category].sample(1, random_state=42)\n",
    "    \n",
    "    # Add to testing set\n",
    "    df_test = pd.concat([df_test, one_data_point], ignore_index=True)\n",
    "    \n",
    "    # Add the rest to the training set\n",
    "    df_train = pd.concat([df_train, df[df['Verifikasi'] != category]])\n",
    "\n",
    "# Display the test data\n",
    "print(\"\\nTest Data:\")\n",
    "print(df_test)\n",
    "\n",
    "# Display the training data\n",
    "print(\"\\nTraining Data:\")\n",
    "print(df_train)\n",
    "\n",
    "# Text Preprocessing\n",
    "vectorizer = CountVectorizer()\n",
    "X_text_train = vectorizer.fit_transform(df_train['Deskripsi'])\n",
    "X_text_test = vectorizer.transform(df_test['Deskripsi'])\n",
    "\n",
    "# Combine text features with numerical features\n",
    "X_train = pd.concat([pd.DataFrame(X_text_train.toarray()), df_train[['Nominal']].astype(str)], axis=1)\n",
    "X_test = pd.concat([pd.DataFrame(X_text_test.toarray()), df_test[['Nominal']].astype(str)], axis=1)\n",
    "\n",
    "# Convert column names to strings\n",
    "X_train.columns = X_train.columns.astype(str)\n",
    "X_test.columns = X_test.columns.astype(str)\n",
    "\n",
    "# Handle missing values in numerical features\n",
    "X_train = X_train.fillna(0)  # Replace NaN with 0 for simplicity\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "# Random Forest Model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, df_train['Verifikasi'])\n",
    "\n",
    "# Prediction\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(df_test['Verifikasi'], y_pred)\n",
    "print(f'\\nAccuracy on Test Data: {accuracy:.2f}')\n",
    "\n",
    "print('\\nClassification Report on Test Data:')\n",
    "print(classification_report(df_test['Verifikasi'], y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "598d8613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Deskripsi  Nominal Verifikasi\n",
      "0                                     Pembayaran SHF      200        SHF\n",
      "1                                Pembayaran S    H F      200        SHF\n",
      "2  Pembyaran S                                   ...      210        SHF\n",
      "3                                          abcabcabc      250        SHF\n",
      "4                        settlement cabang jabotabek      200    BUF/BUP\n",
      "\n",
      "Test Data:\n",
      "                                           Deskripsi  Nominal Verifikasi\n",
      "0  Pembyaran S                                   ...      210        SHF\n",
      "1                                          setlement      500    BUF/BUP\n",
      "2                                         abcabacaca  2000000    fidusia\n",
      "3                                          pi nal ty  3000000    pinalty\n",
      "4                  u     !@#     m    !@#       k  3  3000000       umk3\n",
      "\n",
      "Training Data:\n",
      "                      Deskripsi  Nominal Verifikasi\n",
      "4   settlement cabang jabotabek      200    BUF/BUP\n",
      "5            sett      tle ment      300    BUF/BUP\n",
      "6                     setlement      500    BUF/BUP\n",
      "7                     setelment  1000000    BUF/BUP\n",
      "8                       fiducia  2000000    fidusia\n",
      "..                          ...      ...        ...\n",
      "11                   abcabacaca  2100000    fidusia\n",
      "12                      pinalti  1000000    pinalty\n",
      "13                      pinalty  2000000    pinalty\n",
      "14                    pi nal ty  3000000    pinalty\n",
      "15                    pi nal ty  3000000    pinalty\n",
      "\n",
      "[80 rows x 3 columns]\n",
      "\n",
      "Accuracy on Test Data: 1.00\n",
      "\n",
      "Classification Report on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     BUF/BUP       1.00      1.00      1.00         1\n",
      "         SHF       1.00      1.00      1.00         1\n",
      "     fidusia       1.00      1.00      1.00         1\n",
      "     pinalty       1.00      1.00      1.00         1\n",
      "        umk3       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         5\n",
      "   macro avg       1.00      1.00      1.00         5\n",
      "weighted avg       1.00      1.00      1.00         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Read data from CSV\n",
    "df = pd.read_csv('dummy.csv')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(df.head())\n",
    "\n",
    "# Initialize empty dataframes for training and testing\n",
    "df_train = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "\n",
    "# Select one random data point per category for testing\n",
    "for category in df['Verifikasi'].unique():\n",
    "    # Get one random data point for testing\n",
    "    one_data_point = df[df['Verifikasi'] == category].sample(1, random_state=8)\n",
    "    \n",
    "    # Add to testing set\n",
    "    df_test = pd.concat([df_test, one_data_point], ignore_index=True)\n",
    "    \n",
    "    # Add the rest to the training set\n",
    "    df_train = pd.concat([df_train, df[df['Verifikasi'] != category]])\n",
    "\n",
    "# Display the test data\n",
    "print(\"\\nTest Data:\")\n",
    "print(df_test)\n",
    "\n",
    "# Display the training data\n",
    "print(\"\\nTraining Data:\")\n",
    "print(df_train)\n",
    "\n",
    "# Text Preprocessing\n",
    "vectorizer = CountVectorizer()\n",
    "X_text_train = vectorizer.fit_transform(df_train['Deskripsi'])\n",
    "X_text_test = vectorizer.transform(df_test['Deskripsi'])\n",
    "\n",
    "# Combine text features with numerical features\n",
    "X_train = pd.concat([pd.DataFrame(X_text_train.toarray()), df_train[['Nominal']].astype(str).reset_index(drop=True)], axis=1)\n",
    "X_test = pd.concat([pd.DataFrame(X_text_test.toarray()), df_test[['Nominal']].astype(str).reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Convert column names to strings\n",
    "X_train.columns = X_train.columns.astype(str)\n",
    "X_test.columns = X_test.columns.astype(str)\n",
    "\n",
    "# Handle missing values in numerical features\n",
    "X_train = X_train.fillna(0)  # Replace NaN with 0 for simplicity\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "# Random Forest Model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, df_train['Verifikasi'])\n",
    "\n",
    "# Prediction\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(df_test['Verifikasi'], y_pred)\n",
    "print(f'\\nAccuracy on Test Data: {accuracy:.2f}')\n",
    "\n",
    "print('\\nClassification Report on Test Data:')\n",
    "print(classification_report(df_test['Verifikasi'], y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "350e04f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "print(len(df_train[\"Deskripsi\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b067d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Deskripsi  Nominal Verifikasi\n",
      "0                                     Pembayaran SHF      200        SHF\n",
      "1                                Pembayaran S    H F      200        SHF\n",
      "2  Pembyaran S                                   ...      210        SHF\n",
      "3                                          abcabcabc      250        SHF\n",
      "4                        settlement cabang jabotabek      200    BUF/BUP\n",
      "\n",
      "Test Data:\n",
      "              Deskripsi  Nominal Verifikasi\n",
      "1   Pembayaran S    H F      200        SHF\n",
      "5    sett      tle ment      300    BUF/BUP\n",
      "9               fiducia  2001000    fidusia\n",
      "13              pinalty  2000000    pinalty\n",
      "17                umk 3  2000000       umk3\n",
      "\n",
      "Training Data:\n",
      "                                            Deskripsi  Nominal Verifikasi\n",
      "3                                           abcabcabc      250        SHF\n",
      "0                                      Pembayaran SHF      200        SHF\n",
      "2   Pembyaran S                                   ...      210        SHF\n",
      "7                                           setelment  1000000    BUF/BUP\n",
      "4                         settlement cabang jabotabek      200    BUF/BUP\n",
      "6                                           setlement      500    BUF/BUP\n",
      "11                                         abcabacaca  2100000    fidusia\n",
      "8                                             fiducia  2000000    fidusia\n",
      "10                                         abcabacaca  2000000    fidusia\n",
      "15                                          pi nal ty  3000000    pinalty\n",
      "12                                            pinalti  1000000    pinalty\n",
      "14                                          pi nal ty  3000000    pinalty\n",
      "19                                     abc umk 3 abca  3000000       umk3\n",
      "16                                              umk 3  1000000       umk3\n",
      "18                  u     !@#     m    !@#       k  3  3000000       umk3\n",
      "\n",
      "Accuracy on Test Data: 0.60\n",
      "\n",
      "Classification Report on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     BUF/BUP       0.00      0.00      0.00         1\n",
      "         SHF       0.50      1.00      0.67         1\n",
      "     fidusia       0.50      1.00      0.67         1\n",
      "     pinalty       0.00      0.00      0.00         1\n",
      "        umk3       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.60         5\n",
      "   macro avg       0.40      0.60      0.47         5\n",
      "weighted avg       0.40      0.60      0.47         5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gusanwa/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gusanwa/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gusanwa/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Read data from CSV\n",
    "df = pd.read_csv('dummy.csv')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(df.head())\n",
    "\n",
    "# Initialize empty dataframes for training and testing\n",
    "df_train = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "\n",
    "# Select one random data point per category for testing\n",
    "for category in df['Verifikasi'].unique():\n",
    "    # Get all data points for the current category\n",
    "    category_data = df[df['Verifikasi'] == category]\n",
    "    \n",
    "    # Split the data for testing and training\n",
    "    category_train, category_test = train_test_split(category_data, test_size=0.25, random_state=42)\n",
    "    \n",
    "    # Add to training set\n",
    "    df_train = pd.concat([df_train, category_train])\n",
    "    \n",
    "    # Add to testing set\n",
    "    df_test = pd.concat([df_test, category_test])\n",
    "\n",
    "# Display the test data\n",
    "print(\"\\nTest Data:\")\n",
    "print(df_test)\n",
    "\n",
    "# Display the training data\n",
    "print(\"\\nTraining Data:\")\n",
    "print(df_train)\n",
    "\n",
    "# Text Preprocessing\n",
    "vectorizer = CountVectorizer()\n",
    "X_text_train = vectorizer.fit_transform(df_train['Deskripsi'])\n",
    "X_text_test = vectorizer.transform(df_test['Deskripsi'])\n",
    "\n",
    "# Combine text features with numerical features\n",
    "X_train = pd.concat([pd.DataFrame(X_text_train.toarray()), df_train[['Nominal']].astype(str).reset_index(drop=True)], axis=1)\n",
    "X_test = pd.concat([pd.DataFrame(X_text_test.toarray()), df_test[['Nominal']].astype(str).reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Convert column names to strings\n",
    "X_train.columns = X_train.columns.astype(str)\n",
    "X_test.columns = X_test.columns.astype(str)\n",
    "\n",
    "# Handle missing values in numerical features\n",
    "X_train = X_train.fillna(0)  # Replace NaN with 0 for simplicity\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "# Random Forest Model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, df_train['Verifikasi'])\n",
    "\n",
    "# Prediction\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(df_test['Verifikasi'], y_pred)\n",
    "print(f'\\nAccuracy on Test Data: {accuracy:.2f}')\n",
    "\n",
    "print('\\nClassification Report on Test Data:')\n",
    "print(classification_report(df_test['Verifikasi'], y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01ca5414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(len(df_train[\"Deskripsi\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b98a05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
