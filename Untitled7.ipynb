{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e502d2d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3], got [0 2 3 4]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 65\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# XGBoost Model\u001b[39;00m\n\u001b[1;32m     64\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m XGBClassifier()\n\u001b[0;32m---> 65\u001b[0m \u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Prediction\u001b[39;00m\n\u001b[1;32m     68\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m xgb_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/sklearn.py:1471\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     expected_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m   1467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1468\u001b[0m     classes\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m expected_classes\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   1469\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (classes \u001b[38;5;241m==\u001b[39m expected_classes)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m   1470\u001b[0m ):\n\u001b[0;32m-> 1471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1472\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1473\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1474\u001b[0m     )\n\u001b[1;32m   1476\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3], got [0 2 3 4]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Read data from CSV\n",
    "df = pd.read_csv('dummy.csv')\n",
    "\n",
    "# Identify unique categories\n",
    "unique_categories = df['Verifikasi'].unique()\n",
    "\n",
    "# Initialize empty dataframes for training and testing\n",
    "df_train = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "\n",
    "# Select one data point per category for testing\n",
    "for category in unique_categories:\n",
    "    # Get one data point for testing\n",
    "    one_data_point = df[df['Verifikasi'] == category].sample(1, random_state=42)\n",
    "    \n",
    "    # Add to testing set\n",
    "    df_test = pd.concat([df_test, one_data_point], ignore_index=True)\n",
    "\n",
    "# Add the rest to the training set\n",
    "df_train = df[~df.index.isin(df_test.index)]\n",
    "\n",
    "# Text Preprocessing using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_text = vectorizer.fit_transform(df_train['Deskripsi'])\n",
    "X_test_text = vectorizer.transform(df_test['Deskripsi'])\n",
    "\n",
    "# Numeric features for training set\n",
    "X_train_numeric = df_train[['Nominal']].astype(str).reset_index(drop=True)\n",
    "\n",
    "# Convert column names to strings\n",
    "X_train_numeric.columns = X_train_numeric.columns.astype(str)\n",
    "\n",
    "# Merge text and numeric features for training set\n",
    "X_train = pd.concat([pd.DataFrame(X_train_text.toarray()), X_train_numeric], axis=1)\n",
    "\n",
    "# Numeric features for test set\n",
    "X_test_numeric = df_test[['Nominal']].astype(str).reset_index(drop=True)\n",
    "\n",
    "# Convert column names to strings\n",
    "X_test_numeric.columns = X_test_numeric.columns.astype(str)\n",
    "\n",
    "# Merge text and numeric features for test set\n",
    "X_test = pd.concat([pd.DataFrame(X_test_text.toarray()), X_test_numeric], axis=1)\n",
    "\n",
    "# Encode labels using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit LabelEncoder on all unique labels from both training and test sets\n",
    "all_labels = pd.concat([df_train['Verifikasi'], df_test['Verifikasi']])\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# Transform labels for training and test sets\n",
    "y_train = label_encoder.transform(df_train['Verifikasi'])\n",
    "y_test = label_encoder.transform(df_test['Verifikasi'])\n",
    "\n",
    "# XGBoost Model\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b95915db",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3], got [0 2 3 4]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 65\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# XGBoost Model\u001b[39;00m\n\u001b[1;32m     64\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m XGBClassifier()\n\u001b[0;32m---> 65\u001b[0m \u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Prediction\u001b[39;00m\n\u001b[1;32m     68\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m xgb_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/sklearn.py:1471\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     expected_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m   1467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1468\u001b[0m     classes\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m expected_classes\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   1469\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (classes \u001b[38;5;241m==\u001b[39m expected_classes)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m   1470\u001b[0m ):\n\u001b[0;32m-> 1471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1472\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1473\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1474\u001b[0m     )\n\u001b[1;32m   1476\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3], got [0 2 3 4]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Read data from CSV\n",
    "df = pd.read_csv('dummy.csv')\n",
    "\n",
    "# Identify unique categories\n",
    "unique_categories = df['Verifikasi'].unique()\n",
    "\n",
    "# Initialize empty dataframes for training and testing\n",
    "df_train = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "\n",
    "# Select one data point per category for testing\n",
    "for category in unique_categories:\n",
    "    # Get one data point for testing\n",
    "    one_data_point = df[df['Verifikasi'] == category].sample(1, random_state=42)\n",
    "    \n",
    "    # Add to testing set\n",
    "    df_test = pd.concat([df_test, one_data_point], ignore_index=True)\n",
    "\n",
    "# Add the rest to the training set\n",
    "df_train = df[~df.index.isin(df_test.index)]\n",
    "\n",
    "# Text Preprocessing using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_text = vectorizer.fit_transform(df_train['Deskripsi'])\n",
    "X_test_text = vectorizer.transform(df_test['Deskripsi'])\n",
    "\n",
    "# Numeric features for training set\n",
    "X_train_numeric = df_train[['Nominal']].astype(str).reset_index(drop=True)\n",
    "\n",
    "# Convert column names to strings\n",
    "X_train_numeric.columns = X_train_numeric.columns.astype(str)\n",
    "\n",
    "# Merge text and numeric features for training set\n",
    "X_train = pd.concat([pd.DataFrame(X_train_text.toarray()), X_train_numeric], axis=1)\n",
    "\n",
    "# Numeric features for test set\n",
    "X_test_numeric = df_test[['Nominal']].astype(str).reset_index(drop=True)\n",
    "\n",
    "# Convert column names to strings\n",
    "X_test_numeric.columns = X_test_numeric.columns.astype(str)\n",
    "\n",
    "# Merge text and numeric features for test set\n",
    "X_test = pd.concat([pd.DataFrame(X_test_text.toarray()), X_test_numeric], axis=1)\n",
    "\n",
    "# Encode labels using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit LabelEncoder on all unique labels from both training and test sets\n",
    "all_labels = pd.concat([df_train['Verifikasi'], df_test['Verifikasi']])\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# Transform labels for training and test sets\n",
    "y_train = label_encoder.transform(df_train['Verifikasi'])\n",
    "y_test = label_encoder.transform(df_test['Verifikasi'])\n",
    "\n",
    "# XGBoost Model\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d75e93cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoded y_test labels:\n",
      "[1 0 2 3 4]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3], got [0 2 3 4]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 69\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# XGBoost Model\u001b[39;00m\n\u001b[1;32m     68\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m XGBClassifier()\n\u001b[0;32m---> 69\u001b[0m \u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Prediction\u001b[39;00m\n\u001b[1;32m     72\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m xgb_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/sklearn.py:1471\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     expected_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m   1467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1468\u001b[0m     classes\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m expected_classes\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   1469\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (classes \u001b[38;5;241m==\u001b[39m expected_classes)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m   1470\u001b[0m ):\n\u001b[0;32m-> 1471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1472\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1473\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1474\u001b[0m     )\n\u001b[1;32m   1476\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3], got [0 2 3 4]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Read data from CSV\n",
    "df = pd.read_csv('dummy.csv')\n",
    "\n",
    "# Identify unique categories\n",
    "unique_categories = df['Verifikasi'].unique()\n",
    "\n",
    "# Initialize empty dataframes for training and testing\n",
    "df_train = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "\n",
    "# Select one data point per category for testing\n",
    "for category in unique_categories:\n",
    "    # Get one data point for testing\n",
    "    one_data_point = df[df['Verifikasi'] == category].sample(1, random_state=42)\n",
    "    \n",
    "    # Add to testing set\n",
    "    df_test = pd.concat([df_test, one_data_point], ignore_index=True)\n",
    "\n",
    "# Add the rest to the training set\n",
    "df_train = df[~df.index.isin(df_test.index)]\n",
    "\n",
    "# Text Preprocessing using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_text = vectorizer.fit_transform(df_train['Deskripsi'])\n",
    "X_test_text = vectorizer.transform(df_test['Deskripsi'])\n",
    "\n",
    "# Numeric features for training set\n",
    "X_train_numeric = df_train[['Nominal']].astype(str).reset_index(drop=True)\n",
    "\n",
    "# Convert column names to strings\n",
    "X_train_numeric.columns = X_train_numeric.columns.astype(str)\n",
    "\n",
    "# Merge text and numeric features for training set\n",
    "X_train = pd.concat([pd.DataFrame(X_train_text.toarray()), X_train_numeric], axis=1)\n",
    "\n",
    "# Numeric features for test set\n",
    "X_test_numeric = df_test[['Nominal']].astype(str).reset_index(drop=True)\n",
    "\n",
    "# Convert column names to strings\n",
    "X_test_numeric.columns = X_test_numeric.columns.astype(str)\n",
    "\n",
    "# Merge text and numeric features for test set\n",
    "X_test = pd.concat([pd.DataFrame(X_test_text.toarray()), X_test_numeric], axis=1)\n",
    "\n",
    "# Encode labels using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit LabelEncoder on all unique labels from both training and test sets\n",
    "all_labels = pd.concat([df_train['Verifikasi'], df_test['Verifikasi']])\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# Transform labels for training and test sets\n",
    "y_train = label_encoder.transform(df_train['Verifikasi'])\n",
    "y_test = label_encoder.transform(df_test['Verifikasi'])\n",
    "\n",
    "# Print y_test labels after encoding\n",
    "print('\\nEncoded y_test labels:')\n",
    "print(y_test)\n",
    "\n",
    "# XGBoost Model\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'\\nAccuracy: {accuracy:.2f}')\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8147164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoded y_test labels:\n",
      "[1 0 2 3 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_110003/4141012642.py:24: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_test = df_test.append(one_data_point, ignore_index=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3], got [0 2 3 4]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 69\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# XGBoost Model\u001b[39;00m\n\u001b[1;32m     68\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m XGBClassifier()\n\u001b[0;32m---> 69\u001b[0m \u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Prediction\u001b[39;00m\n\u001b[1;32m     72\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m xgb_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/sklearn.py:1471\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     expected_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m   1467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1468\u001b[0m     classes\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m expected_classes\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   1469\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (classes \u001b[38;5;241m==\u001b[39m expected_classes)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m   1470\u001b[0m ):\n\u001b[0;32m-> 1471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1472\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1473\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1474\u001b[0m     )\n\u001b[1;32m   1476\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3], got [0 2 3 4]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Read data from CSV\n",
    "df = pd.read_csv('dummy.csv')\n",
    "\n",
    "# Identify unique categories\n",
    "unique_categories = df['Verifikasi'].unique()\n",
    "\n",
    "# Initialize empty dataframes for training and testing\n",
    "df_train = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "\n",
    "# Select one data point per category for testing\n",
    "for category in unique_categories:\n",
    "    # Get one data point for testing\n",
    "    one_data_point = df[df['Verifikasi'] == category].sample(1, random_state=42)\n",
    "    \n",
    "    # Add to testing set\n",
    "    df_test = df_test.append(one_data_point, ignore_index=True)\n",
    "\n",
    "# Add the rest to the training set\n",
    "df_train = df[~df.index.isin(df_test.index)]\n",
    "\n",
    "# Text Preprocessing using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_text = vectorizer.fit_transform(df_train['Deskripsi'])\n",
    "X_test_text = vectorizer.transform(df_test['Deskripsi'])\n",
    "\n",
    "# Numeric features for training set\n",
    "X_train_numeric = df_train[['Nominal']].astype(str).reset_index(drop=True)\n",
    "\n",
    "# Convert column names to strings\n",
    "X_train_numeric.columns = X_train_numeric.columns.astype(str)\n",
    "\n",
    "# Merge text and numeric features for training set\n",
    "X_train = pd.concat([pd.DataFrame(X_train_text.toarray()), X_train_numeric], axis=1)\n",
    "\n",
    "# Numeric features for test set\n",
    "X_test_numeric = df_test[['Nominal']].astype(str).reset_index(drop=True)\n",
    "\n",
    "# Convert column names to strings\n",
    "X_test_numeric.columns = X_test_numeric.columns.astype(str)\n",
    "\n",
    "# Merge text and numeric features for test set\n",
    "X_test = pd.concat([pd.DataFrame(X_test_text.toarray()), X_test_numeric], axis=1)\n",
    "\n",
    "# Encode labels using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit LabelEncoder on all unique labels from both training and test sets\n",
    "all_labels = pd.concat([df_train['Verifikasi'], df_test['Verifikasi']])\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# Transform labels for training and test sets\n",
    "y_train = label_encoder.transform(df_train['Verifikasi'])\n",
    "y_test = label_encoder.transform(df_test['Verifikasi'])\n",
    "\n",
    "# Print y_test labels after encoding\n",
    "print('\\nEncoded y_test labels:')\n",
    "print(y_test)\n",
    "\n",
    "# XGBoost Model\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'\\nAccuracy: {accuracy:.2f}')\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7866b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Read data from CSV\n",
    "df = pd.read_csv('dummy.csv')\n",
    "\n",
    "# Identify unique categories\n",
    "unique_categories = df['Verifikasi'].unique()\n",
    "\n",
    "# Initialize empty dataframes for training and testing\n",
    "df_train = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "\n",
    "# Select one data point per category for testing\n",
    "for category in unique_categories:\n",
    "    # Get one data point for testing\n",
    "    one_data_point = df[df['Verifikasi'] == category].sample(1, random_state=42)\n",
    "    \n",
    "    # Add to testing set\n",
    "    df_test = df_test.append(one_data_point, ignore_index=True)\n",
    "\n",
    "# Add the rest to the training set\n",
    "df_train = df[~df.index.isin(df_test.index)]\n",
    "\n",
    "# Text Preprocessing using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_text = vectorizer.fit_transform(df_train['Deskripsi'])\n",
    "X_test_text = vectorizer.transform(df_test['Deskripsi'])\n",
    "\n",
    "# Numeric features for training set\n",
    "X_train_numeric = df_train[['Nominal']].astype(str).reset_index(drop=True)\n",
    "\n",
    "# Convert column names to strings\n",
    "X_train_numeric.columns = X_train_numeric.columns.astype(str)\n",
    "\n",
    "# Merge text and numeric features for training set\n",
    "X_train = pd.concat([pd.DataFrame(X_train_text.toarray()), X_train_numeric], axis=1)\n",
    "\n",
    "# Numeric features for test set\n",
    "X_test_numeric = df_test[['Nominal']].astype(str).reset_index(drop=True)\n",
    "\n",
    "# Convert column names to strings\n",
    "X_test_numeric.columns = X_test_numeric.columns.astype(str)\n",
    "\n",
    "# Merge text and numeric features for test set\n",
    "X_test = pd.concat([pd.DataFrame(X_test_text.toarray()), X_test_numeric], axis=1)\n",
    "\n",
    "# Encode labels using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit LabelEncoder on all unique labels from both training and test sets\n",
    "all_labels = pd.concat([df_train['Verifikasi'], df_test['Verifikasi']])\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# Transform labels for training and test sets\n",
    "y_train = label_encoder.transform(df_train['Verifikasi'])\n",
    "y_test = label_encoder.transform(df_test['Verifikasi'])\n",
    "\n",
    "# Print y_test labels after encoding\n",
    "print('\\nEncoded y_test labels:')\n",
    "print(y_test)\n",
    "\n",
    "# XGBoost Model\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'\\nAccuracy: {accuracy:.2f}')\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3c42eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoded y_test labels:\n",
      "[1 4 3 1]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:Nominal: object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# XGBoost Model\u001b[39;00m\n\u001b[1;32m     36\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m XGBClassifier()\n\u001b[0;32m---> 37\u001b[0m \u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Prediction\u001b[39;00m\n\u001b[1;32m     40\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m xgb_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/sklearn.py:1500\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1489\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_class\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_\n\u001b[1;32m   1491\u001b[0m (\n\u001b[1;32m   1492\u001b[0m     model,\n\u001b[1;32m   1493\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1498\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1499\u001b[0m )\n\u001b[0;32m-> 1500\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m \u001b[43m_wrap_evaluation_matrices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1510\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1512\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1513\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_qid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_dmatrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1515\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1517\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[1;32m   1520\u001b[0m     params,\n\u001b[1;32m   1521\u001b[0m     train_dmatrix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m   1531\u001b[0m )\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/sklearn.py:521\u001b[0m, in \u001b[0;36m_wrap_evaluation_matrices\u001b[0;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_evaluation_matrices\u001b[39m(\n\u001b[1;32m    502\u001b[0m     missing: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[1;32m    503\u001b[0m     X: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    517\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[1;32m    518\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, List[Tuple[Any, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m    519\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\u001b[39;00m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;124;03m    way.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 521\u001b[0m     train_dmatrix \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dmatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m     n_validation \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m eval_set \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(eval_set)\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_or_none\u001b[39m(meta: Optional[Sequence], name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Sequence:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/sklearn.py:958\u001b[0m, in \u001b[0;36mXGBModel._create_dmatrix\u001b[0;34m(self, ref, **kwargs)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _can_use_qdm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_method) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbooster \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 958\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mQuantileDMatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnthread\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_bin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_bin\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[1;32m    962\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/core.py:1529\u001b[0m, in \u001b[0;36mQuantileDMatrix.__init__\u001b[0;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, max_bin, ref, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, data_split_mode)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m   1510\u001b[0m         info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1511\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m info \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1522\u001b[0m         )\n\u001b[1;32m   1523\u001b[0m     ):\n\u001b[1;32m   1524\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1525\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf data iterator is used as input, data like label should be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1526\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecified as batch argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1527\u001b[0m         )\n\u001b[0;32m-> 1529\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_lower_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_lower_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_upper_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_upper_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/core.py:1588\u001b[0m, in \u001b[0;36mQuantileDMatrix._init\u001b[0;34m(self, data, ref, enable_categorical, **meta)\u001b[0m\n\u001b[1;32m   1576\u001b[0m config \u001b[38;5;241m=\u001b[39m make_jcargs(\n\u001b[1;32m   1577\u001b[0m     nthread\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnthread, missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing, max_bin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_bin\n\u001b[1;32m   1578\u001b[0m )\n\u001b[1;32m   1579\u001b[0m ret \u001b[38;5;241m=\u001b[39m _LIB\u001b[38;5;241m.\u001b[39mXGQuantileDMatrixCreateFromCallback(\n\u001b[1;32m   1580\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1581\u001b[0m     it\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1586\u001b[0m     ctypes\u001b[38;5;241m.\u001b[39mbyref(handle),\n\u001b[1;32m   1587\u001b[0m )\n\u001b[0;32m-> 1588\u001b[0m \u001b[43mit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1589\u001b[0m \u001b[38;5;66;03m# delay check_call to throw intermediate exception first\u001b[39;00m\n\u001b[1;32m   1590\u001b[0m _check_call(ret)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/core.py:576\u001b[0m, in \u001b[0;36mDataIter.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    574\u001b[0m exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 576\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/core.py:557\u001b[0m, in \u001b[0;36mDataIter._handle_exception\u001b[0;34m(self, fn, dft_ret)\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dft_ret\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;66;03m# Defer the exception in order to return 0 and stop the iteration.\u001b[39;00m\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;66;03m# Exception inside a ctype callback function has no effect except\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;66;03m# for printing to stderr (doesn't stop the execution).\u001b[39;00m\n\u001b[1;32m    562\u001b[0m     tb \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/core.py:641\u001b[0m, in \u001b[0;36mDataIter._next_wrapper.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_ref \u001b[38;5;241m=\u001b[39m ref\n\u001b[1;32m    640\u001b[0m \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m--> 641\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_exception(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/data.py:1280\u001b[0m, in \u001b[0;36mSingleBatchInternalIter.next\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mit \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1280\u001b[0m \u001b[43minput_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/core.py:624\u001b[0m, in \u001b[0;36mDataIter._next_wrapper.<locals>.input_data\u001b[0;34m(data, feature_names, feature_types, **kwargs)\u001b[0m\n\u001b[1;32m    622\u001b[0m     new, cat_codes, feature_names, feature_types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_temporary_data\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 624\u001b[0m     new, cat_codes, feature_names, feature_types \u001b[38;5;241m=\u001b[39m \u001b[43m_proxy_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_enable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;66;03m# Stage the data, meta info are copied inside C++ MetaInfo.\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_temporary_data \u001b[38;5;241m=\u001b[39m (new, cat_codes, feature_names, feature_types)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/data.py:1315\u001b[0m, in \u001b[0;36m_proxy_transform\u001b[0;34m(data, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[1;32m   1314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_pandas_df(data):\n\u001b[0;32m-> 1315\u001b[0m     arr, feature_names, feature_types \u001b[38;5;241m=\u001b[39m \u001b[43m_transform_pandas_df\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_types\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1318\u001b[0m     arr, _ \u001b[38;5;241m=\u001b[39m _ensure_np_dtype(arr, arr\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr, \u001b[38;5;28;01mNone\u001b[39;00m, feature_names, feature_types\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/data.py:490\u001b[0m, in \u001b[0;36m_transform_pandas_df\u001b[0;34m(data, enable_categorical, feature_names, feature_types, meta, meta_type)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dtype \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtypes:\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[1;32m    485\u001b[0m         (dtype\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m _pandas_dtype_mapper)\n\u001b[1;32m    486\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m is_pd_sparse_dtype(dtype)\n\u001b[1;32m    487\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (is_pd_cat_dtype(dtype) \u001b[38;5;129;01mand\u001b[39;00m enable_categorical)\n\u001b[1;32m    488\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m is_pa_ext_dtype(dtype)\n\u001b[1;32m    489\u001b[0m     ):\n\u001b[0;32m--> 490\u001b[0m         \u001b[43m_invalid_dataframe_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_pa_ext_dtype(dtype):\n\u001b[1;32m    492\u001b[0m         pyarrow_extension \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/data.py:308\u001b[0m, in \u001b[0;36m_invalid_dataframe_dtype\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    306\u001b[0m type_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame.dtypes for data must be int, float, bool or category.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_err\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_ENABLE_CAT_ERR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m--> 308\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:Nominal: object"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Read data from CSV\n",
    "df = pd.read_csv('dummy.csv')\n",
    "\n",
    "# Text Preprocessing using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_text = vectorizer.fit_transform(df['Deskripsi'])\n",
    "\n",
    "# Numeric features\n",
    "X_numeric = df[['Nominal']].astype(str).reset_index(drop=True)\n",
    "\n",
    "# Convert column names to strings\n",
    "X_numeric.columns = X_numeric.columns.astype(str)\n",
    "\n",
    "# Merge text and numeric features\n",
    "X = pd.concat([pd.DataFrame(X_text.toarray()), X_numeric], axis=1)\n",
    "\n",
    "# Encode labels using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['Verifikasi'])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print y_test labels after encoding\n",
    "print('\\nEncoded y_test labels:')\n",
    "print(y_test)\n",
    "\n",
    "# XGBoost Model\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'\\nAccuracy: {accuracy:.2f}')\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b571a236",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
